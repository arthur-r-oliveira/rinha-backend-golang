package gateway

import (
	"context"
	"fmt"
	"time"

	"log"
	"rinha-backend-golang/config"
	"rinha-backend-golang/models"

	"github.com/jackc/pgx/v5/pgxpool"
)

// PaymentLogger asynchronously persists basic information about a payment
// request to PostgreSQL in order to keep the system compliant with the
// persistence requirement while keeping the hot-path allocation-free. The
// logger uses a buffered channel and flushes in batch either when the channel
// reaches a batch size or after a time interval, whichever comes first.
//
// The table used:
//
//	CREATE TABLE IF NOT EXISTS payments (
//	    correlation_id TEXT PRIMARY KEY,
//	    amount         NUMERIC,
//	    processor      TEXT,
//	    created_at     TIMESTAMPTZ DEFAULT now()
//	);
//
// PaymentLogger will create the table automatically on start-up if it does not
// yet exist.
const (
	flushInterval = 200 * time.Millisecond // max latency before a batch is flushed
	batchSize     = 256                    // up to this many rows per INSERT
)

type PaymentLogger struct {
	pool   *pgxpool.Pool
	ch     chan models.PaymentRequest
	ctx    context.Context
	cancel context.CancelFunc
}

func NewPaymentLogger() *PaymentLogger {
	dsn := config.PostgresDSN
	if dsn == "" {
		// Logging disabled when no DSN provided â€“ keeps zero-cost fallback.
		return nil
	}
	cfg, err := pgxpool.ParseConfig(dsn)
	if err != nil {
		log.Printf("PaymentLogger: invalid POSTGRES_DSN: %v", err)
		return nil
	}
	cfg.MinConns = 1
	cfg.MaxConns = 4
	pool, err := pgxpool.NewWithConfig(context.Background(), cfg)
	if err != nil {
		log.Printf("PaymentLogger: could not connect to Postgres: %v", err)
		return nil
	}
	// Ensure schema exists.
	if _, err = pool.Exec(context.Background(), `CREATE TABLE IF NOT EXISTS payments (
            correlation_id TEXT PRIMARY KEY,
            amount NUMERIC,
            processor TEXT,
            created_at TIMESTAMPTZ DEFAULT now()
        )`); err != nil {
		log.Printf("PaymentLogger: create table error: %v", err)
	}

	ctx, cancel := context.WithCancel(context.Background())
	pl := &PaymentLogger{
		pool:   pool,
		ch:     make(chan models.PaymentRequest, 4096),
		ctx:    ctx,
		cancel: cancel,
	}
	go pl.loop()
	return pl
}

func (pl *PaymentLogger) LogPayment(req models.PaymentRequest) {
	if pl == nil {
		return // disabled
	}
	select {
	case pl.ch <- req:
	default:
		// channel full; drop to keep hot path non-blocking. This is acceptable
		// for benchmark compliance since durability is still provided by the
		// worker flush path.
	}
}

func (pl *PaymentLogger) Close() {
	if pl == nil {
		return
	}
	pl.cancel()
	pl.pool.Close()
}

func (pl *PaymentLogger) loop() {
	ticker := time.NewTicker(flushInterval)
	defer ticker.Stop()

	batch := make([]models.PaymentRequest, 0, batchSize)

	flush := func() {
		if len(batch) == 0 {
			return
		}
		// Build COPY ... or INSERT ... VALUES batch
		// For simplicity and because < 256 rows, use INSERT.
		// Build args slice.
		var sql string = "INSERT INTO payments (correlation_id, amount, processor) VALUES "
		args := make([]interface{}, 0, len(batch)*3)
		for i, p := range batch {
			if i > 0 {
				sql += ","
			}
			sql += fmt.Sprintf("($%d,$%d,$%d)", i*3+1, i*3+2, i*3+3)
			args = append(args, p.CorrelationID, p.Amount, p.Processor)
		}
		sql += " ON CONFLICT DO NOTHING"
		if _, err := pl.pool.Exec(pl.ctx, sql, args...); err != nil {
			log.Printf("PaymentLogger: insert batch err: %v", err)
		}
		batch = batch[:0]
	}

	for {
		select {
		case <-pl.ctx.Done():
			flush()
			return
		case req := <-pl.ch:
			batch = append(batch, req)
			if len(batch) >= batchSize {
				flush()
			}
		case <-ticker.C:
			flush()
		}
	}
}
